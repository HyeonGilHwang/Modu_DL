{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "셋째마당 신경망의 이해.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOUuLdfWK82pXtqempdrMgF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyeonGilHwang/Modu_DL/blob/main/%EC%85%8B%EC%A7%B8%EB%A7%88%EB%8B%B9_%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98_%EC%9D%B4%ED%95%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0mi0eettmmf"
      },
      "source": [
        "# 6장 퍼셉트론\n",
        "- 뉴런과 뉴런이 서로 새로운 연결을 만들기도 하고 필요에 따라 위치를 바꾸는 것처럼, 여러 층의 퍼셉트론을 서로 연결시키고 복작하게 조합하여 주어진 입력 값에 대한 판단을 하게 하는 것이 바로 신경망의 기본 구조다.\n",
        "- 신경망을 이루는 가장 중요한 기본 단위는 퍼셉트론(perceptron)이다.\n",
        "- 퍼셉트론은 입력 값과 활성화 함수를 사용해 출력 값을 다음으로 넘기는 가장 작은 신경망 단위다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eauch3FCvs1X"
      },
      "source": [
        "## 1 가중치, 가중합, 바이어스, 활성화 함수\n",
        "- 기울기 a나 y절편 b와 같은 용어를 퍼셉트론의 개념에 맞춰 표현하면 다음과 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cDxXKnqv70u"
      },
      "source": [
        "$$y = ax +b$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Hi5e8KCXPq"
      },
      "source": [
        "- $a$는 기울기, $b$는 $y$절편이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSe_OtqBwOq9"
      },
      "source": [
        "$$\\rightarrow y = wx + b $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBtP_KJlCgJQ"
      },
      "source": [
        "- $w$는 가중치, $b$는 바이어스다.\n",
        "- 입력값($x$)와 가중치($w$)의 곱을 모든 더한 다음 바이어스($b$)를 더한 값을 가중합이라 한다.\n",
        "- 가중합의 결과를 놓고 1 또는 0을 출력해서 다음으로 보낸다. 여기서 이를 판단하는 함수가 활성화 함수(activation function)라 한다.\n",
        "- p103 그림6-1 참고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu5pKk2Cw0El"
      },
      "source": [
        "\n",
        "\n",
        "1.   항목 추가\n",
        "2.   항목 추가\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTpannsixop_"
      },
      "source": [
        "## 2 퍼셉트론의 과제\n",
        "- 퍼셉트론 역시 선을 긋는 작업이라 할 수 있다.\n",
        "- 선을 아무리 그어도 해결되지 않는 상황이 있다.\n",
        "- p105 그림6-3 참고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSZPikwvyGVd"
      },
      "source": [
        "## 3 XOR 문제\n",
        "- 위 한계를 설명할 때 XOR(exclusive OR) 문제라 한다.\n",
        "- XOR 문제는 논리 회로에 등장하는 개념이다.\n",
        "- 컴퓨터는 두 가지의 디지털 값, 즉 0과 1을 입력해 하나의 값을 출력하는 회로가 모여 만들어지는데, 이 회로를 '게이트(gate)'라고 한다.\n",
        "- AND 게이트는 x1과 x2 둘 다 1일 때 결괏값이 1로 출력된다.\n",
        "- OR 게이트는 둘 중 하나라도 1이면 결괏값이 1로 출력된다.\n",
        "- XOR 게이트는 둘 중 하나만 1일 때 1이 출력된다.\n",
        "- p106 표6-1 참고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvGuLvTfzOVl"
      },
      "source": [
        "# 7장 다층 퍼셉트론\n",
        "- 좌표 평면 자체에 변화를 주어 한 번에 계산할 수 있어야한다. 이를 가능하게 하려면 은닉층(hidden layer)를 만들면 된다.\n",
        "- 은닉층을 만들어 공간을 왜곡하면 두 영역을 가로지르는 선이 직선으로 바뀐다.\n",
        "- p107~108 참고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ1LVbd40TdG"
      },
      "source": [
        "## 1 다층 퍼셉트론의 설계\n",
        "- 숨어있는 은닉층으로 퍼셉트론이 각각 자신의 가중치와 바이어스 값을 보내고, 이 은닉층에서 모인 값이 한 번 더 시그모이드 함수(기호로 $\\sigma$)를 이용해 최종 값으로 결과를 보낸다. \n",
        "- 은닉층에 모이는 중간 정거장을 노드(node)라고 하며, 여기서는 $n_1$, $n_2$로 표현하였다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrByKsv31Ipk"
      },
      "source": [
        "$$n_1 = \\sigma (x_1 w_{11} + x_2 w_{21} + b_1)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jETADEkB1Xr3"
      },
      "source": [
        "$$n_2 = \\sigma (x_1 w_{12} + x_2 w_{22} + b_2)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GThzde7D1gT9"
      },
      "source": [
        "- 이 결괏값이 출력층에 보내진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvMPLIXD1nzf"
      },
      "source": [
        "$$y_{out} = \\sigma (n_1 w_{31} + n_2 w_{32} + b_3)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKEtchRU13uf"
      },
      "source": [
        "- 2차원 배열로 가중치와 바이어스를 표시할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRwEVO9p180u"
      },
      "source": [
        "$$W(1) = \n",
        "\\begin{pmatrix}  \n",
        "w_{11} & w_{12} \\\\\n",
        "w_{21} & w_{22} \\\\\n",
        "\\end{pmatrix}\\;\\;\\;B(1) = \n",
        "\\begin{pmatrix}\n",
        "b_1 \\\\\n",
        "b_2  \n",
        "\\end{pmatrix}\n",
        "$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JhLeSZn29kC"
      },
      "source": [
        "$$W(2) = \n",
        "\\begin{pmatrix}  \n",
        "w_{31}  \\\\\n",
        "w_{32} \\\\\n",
        "\\end{pmatrix}\\;\\;\\;B(2) = \n",
        "\\begin{pmatrix}\n",
        "b_3 \n",
        "\\end{pmatrix}\n",
        "$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9nAhna_3Jup"
      },
      "source": [
        "## 2 XOR 문제의 해결\n",
        "- 다음과 같이 각 변숫값을 정하고 이를 이용해 XOR 문제를 해결해보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NTq6w_V3fmR"
      },
      "source": [
        "$$W(1) = \n",
        "\\begin{pmatrix}  \n",
        "-2 & 2 \\\\\n",
        "-2 & 2 \\\\\n",
        "\\end{pmatrix}\\;\\;\\;B(1) = \n",
        "\\begin{pmatrix}\n",
        "3 \\\\\n",
        "-1  \n",
        "\\end{pmatrix}\n",
        "$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjfnAOop3uHQ"
      },
      "source": [
        "$$W(2) = \n",
        "\\begin{pmatrix}  \n",
        "1  \\\\\n",
        "1 \\\\\n",
        "\\end{pmatrix}\\;\\;\\;B(2) = \n",
        "\\begin{pmatrix}\n",
        "-1 \n",
        "\\end{pmatrix}\n",
        "$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytPsHgzO4TgH"
      },
      "source": [
        "|$x_1$|$x_2$|$n_1$|$n_2$|$y_{out}$|우리가 원하는 값|\n",
        "|:----:|:----:|:----:|:----:|:----:|:----:|\n",
        "|0|0|$\\sigma$(0$*$(-2)+0$*$(-2)+3) = 1|$\\sigma$(0$*$ 2+0 $*$ 2 -1) = 0|$\\sigma$(1$*$ 1+0 $*$ 1 -1) = 0|0|\n",
        "|0|1|$\\sigma$(0$*$(-2)+1$*$(-2)+3) = 1|$\\sigma$(0$*$ 2+1 $*$ 2 -1) = 1|$\\sigma$(1$*$ 1+1 $*$ 1 -1) = 1|1|\n",
        "|1|0|$\\sigma$(1$*$(-2)+0$*$(-2)+3) = 1|$\\sigma$(1$*$ 2+0 $*$ 2 -1) = 1|$\\sigma$(1$*$ 1+1 $*$ 1 -1) = 1|1|\n",
        "|1|1|$\\sigma$(1$*$(-2)+1$*$(-2)+3) = 0|$\\sigma$(1$*$ 2+1 $*$ 2 -1) = 1|$\\sigma$(0$*$ 1+1 $*$ 1 -1) = 0|0|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKGKTorv8Mnu"
      },
      "source": [
        "## 3 코딩으로 XOR 문제 해결하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rBy3i36s1s7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "w11 = np.array([-2, -2])\n",
        "w12 = np.array([2, 2])\n",
        "w2 = np.array([1, 1])\n",
        "b1 = 3\n",
        "b2 = -1\n",
        "b3 = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvHsbMi38yxM"
      },
      "source": [
        "# 퍼셉트론 함수\n",
        "def MLP(x, w, b):\n",
        "  y = np.sum(w*x) + b\n",
        "  if y <= 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhQfqL0b9ByY"
      },
      "source": [
        "# NAND 게이트 \n",
        "# n1 구할때\n",
        "def NAND(x1, x2):\n",
        "  return MLP(np.array([x1, x2]), w11, b1)\n",
        "\n",
        "# OR 게이트\n",
        "# n2 구할때\n",
        "def OR(x1, x2):\n",
        "  return MLP(np.array([x1, x2]), w12, b2)\n",
        "\n",
        "# AND 게이트\n",
        "# y_out 구할때\n",
        "def AND(x1, x2):\n",
        "  return MLP(np.array([x1, x2]), w2, b3)\n",
        "\n",
        "# XOR 게이트\n",
        "def XOR(x1, x2):\n",
        "  return AND(NAND(x1, x2), OR(x1, x2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pml218D-PHC",
        "outputId": "9d6c642d-c247-4348-9248-6f85f1985aec"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    for x in [(0, 0), (1, 0), (0, 1), (1, 1)]:\n",
        "        y = XOR(x[0], x[1])\n",
        "        print(\"입력 값: \" + str(x) + \" 출력 값: \" + str(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 값: (0, 0) 출력 값: 0\n",
            "입력 값: (1, 0) 출력 값: 1\n",
            "입력 값: (0, 1) 출력 값: 1\n",
            "입력 값: (1, 1) 출력 값: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVlyG2c_b3z5"
      },
      "source": [
        "# 8장 오차 역전파\n",
        "- 오차 역전파는 경사 하강법의 확장 개념이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCAwuZfjcK2l"
      },
      "source": [
        "## 1 오차 역전파의 개념\n",
        "- 앞서 배운 경사 하강법은 입력과 출력이 하나일 때, 즉 '단일 퍼셉트론'일 겨우다.\n",
        "- 다층 퍼셉트론 역시 결괏값의 오차를 구해 이를 토대로 하나 앞선 가중치를 차례로 거슬러 올라가며 조정한다.\n",
        "- 다층 퍼셉트론에서의 최적화 과정을 오차 역전파(back propagation)라고 부른다.\n",
        "- 오차 역전파의 구동 방식은 다음과 같다.\n",
        "  - 임의 초기 가중치($W$)를 준 뒤 결과($y_{out}$)를 계산한다.\n",
        "  - 계산 결과와 우리가 원하는 값 사이의 오차를 구한다.\n",
        "  - 경사 하강법을 이용해 바로 앞 가중치를 오차가 작아지는 방향으로 업데이트한다.\n",
        "  - 위 과정을 더이상 오차가 줄어들지 않을 때까지 반복한다.\n",
        "- 오차 역전파를 다른 방식으로 표현하면 가중치에서 기울기를 빼도 값의 변화가 없을 때까지 계속해서 가중치 수정 작업을 반복하는 것이다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wsGh5Xjd6nt"
      },
      "source": [
        "$$W(t+1) = W_t - \\frac{\\partial Error}{\\partial W}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCkg92AceS6V"
      },
      "source": [
        "## 2 코딩으로 확인하는 오차 역전파\n",
        "- 입력된 실제 값과 다층 퍼셉트론의 계산 결과를 비교하여 가중치를 역전파 방식으로 수정해 가능 코딩은 다음과 같다.\n",
        "  - 환경 변수 지정: 환경 변수에는 입력 값과 타깃 결괏값이 포함된 데이터셋, 학습률 등이 포함된다. 또한, 황성화 함수와 가중치 등도 선언되어야 한다.\n",
        "  - 신경말 실행: 초깃값을 입력하여 활성화 함수와 가중치를 거쳐 결괏값이 나오게 한다.\n",
        "  - 결과를 실제 값과 비교: 오차를 비교\n",
        "  - 역전파 실행: 출력층과 은닉층의 가중치를 수정한다.\n",
        "  - 결과 출력\n",
        "- 이에 대한 해설은 '심화 학습 2. 파이썬 코드로 확인하는 신경망'에 자세히 나와 있다.\n",
        "- p119 그림8-3 참고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSVUwET0fap6"
      },
      "source": [
        "# 9장 신경망에서 딥러닝으로\n",
        "- 다층 퍼셉트론이 오차 역전파를 만나 신경망이 되고, 신경망은 XOR문제를 해결한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAcFQcNTfvJf"
      },
      "source": [
        "## 1 기울기 소실 문제와 활성화 함수\n",
        "- 오차 역전파는 출력층으로부터 앞으로 되돌아가며 각 층의 가중치를 수정하는 방법이다.\n",
        "- 층이 늘어나면서 역전파를 통해 전달되는 기울기의 값이 점점 작아져 맨 처음 층까지 전달되지 않는 기울기 소실(vanishing gradient)문제가 발생한다.\n",
        "- 이는 활성화 함수로 사용된 시그모이드 함수의 특성 떄문이다. 시그모이드 함수를 미분하면 최대치가 0.3이다. 1보다 작으므로 계속 곱하다 보면 0에 가까워진다. 따라서 층을 거칠수록 기울기가 사라져 가중치를 수정하기 어려워진다.\n",
        "- 이를 해결하고자 시그모이드가 아닌 여러 함수로 대체하기 시작한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdoLqeKth55m"
      },
      "source": [
        "- 시그모이드 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7klQPVNgl9I"
      },
      "source": [
        "$$f(x) = \\frac{1}{1+e^{-x}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LFctoa8gudO"
      },
      "source": [
        "- 하이퍼블릭 탄젠트 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VF8p0lSg04R"
      },
      "source": [
        "$$f(x) = tanh(x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIhtY7jkg4w6"
      },
      "source": [
        "- 렐루 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFb7dYKGhDMR"
      },
      "source": [
        "$$f(x) =\n",
        "\\begin{pmatrix}\n",
        "x \\;\\;(x>0)\\\\\n",
        "0 \\;\\;(x \\leq 0)\n",
        "\\end{pmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4flxfSyEhwbl"
      },
      "source": [
        "- 소프트플러스 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PckxPPbDhylW"
      },
      "source": [
        "$$f(x) = log(1 + e^x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8Y1Wq_NiCWc"
      },
      "source": [
        "- 시그모이드 함수의 범위를 -1에서 1로 확장한 개념인 하이퍼볼린 탄젠트 함수는 미분한 값의 범위가 함께 확장되는 효과를 가져온다. 하지만 여전히 1보다 작은 값이 존재하므로 기울기 소실 문제는 사라지지 않는다.\n",
        "- 렐루함수는 시그모이드 함수의 대안으로 가장 많이 사용되는 활성화 함수다. x가 0보다 크면 미분값이 1이 된다. 따라서 여러 은닉층이 곱해지더라도 맨 처음 층까지 사라지지 않고 남는다.\n",
        "- 소프트플러스 함수는 렐루의 0이 되는 순간을 완화한 변형된 함수이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgEiC5pAi0ne"
      },
      "source": [
        "## 2 속도와 정확도 문제를 해결하는 고급 경사 하강법\n",
        "- 경사하강법은 정확하게 가중치를 찾아가지만, 한 번 업데이트할 때마다 전체 데이터를 미분해야 하므로 계산량이 매우 많다.\n",
        "- 이러한 점을 보완한 고급 경사 하강법이 등장한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDu9GRYYjOR6"
      },
      "source": [
        "- **확률적 경사 하강법(Stochastic Gradient Decent, SGD)**는 전체 데이터를 사용하는 것이 아니라, 랜덤하게 추출한 일부 데이터를 사용한다. 랜덤한 일부 데이터를 사용하는 만큼 확률적 경사 하강법은 중간 결과의 진폭이 크고 불안정해 보일 수도 있다. 하지만 속도가 확연히 빠르면서 최적 해에 근사한 값도 찾아낸다는 장점이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G07GBiqj0PA"
      },
      "source": [
        "- **모멘텀(momentum) SGD**은 말 그대로 경사 하강법에 탄력을 더해 주는 것이다. 경사 하강법과 마찬가지로 매번 기울기를 구하지만, 이를 통해 오차를 수정하기 전 바로 앞 수정 값과 방향을 참고하여 같은 방향으로 일정한 비율만 수정되게 하는 방법이다. 따라서 지그재그로 일어나느 현상이 줄어들고 일정 비율만큼만 다음 값을 결정하므로 관성의 효과를 나타낸다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y3EUO2YjxmX"
      },
      "source": [
        "- 이 외에도 네스테로프 모멘텀(NAG), 아다그라드(Adagrad), 알엠에스프롭(RMSProp), 아담(Adam)이 있다.\n",
        "- 아담은 현재 가장 많이 사용되는 고급 경사 하강법이다.\n",
        "- p124 표9-1 참고\n"
      ]
    }
  ]
}